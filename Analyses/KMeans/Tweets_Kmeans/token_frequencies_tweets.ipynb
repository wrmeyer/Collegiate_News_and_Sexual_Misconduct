{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "location = str(os.getcwd())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "45982\n"
     ]
    }
   ],
   "source": [
    "f = (location[:-29] + \"Tweets\\\\tweets_cleaned.csv\")\n",
    "df = pd.read_csv(f)\n",
    "df = df.to_dict(\"index\")\n",
    "print(len(df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "21027\n"
     ]
    }
   ],
   "source": [
    "#cleaning body text\n",
    "data = []\n",
    "\n",
    "for i in range(len(df)):\n",
    "    text_clean = \"\"\n",
    "    text = df[i][\"text\"]\n",
    "    text = text.split(\" \")\n",
    "    for item in text:\n",
    "        if \"@\" not in item:\n",
    "            text_clean += item\n",
    "            text_clean += \" \"\n",
    "    if text_clean not in data:\n",
    "        data.append(text_clean)\n",
    "print(len(data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import pandas as pd\n",
    "import nltk"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tokenizing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "455583\n"
     ]
    }
   ],
   "source": [
    "def list_tokens(Data):\n",
    "    \"\"\"\n",
    "    This function will convert Articles into list of tokens(either alpha or numeric)\n",
    "    \n",
    "    arguments:\n",
    "        input_text: \"Data\" of type \"pandas Dataframe\". \n",
    "                    \n",
    "    return:\n",
    "        value: \"list_of_tokens\" after splitting all the articles in \n",
    "                \"Processed_Content\" attribute into list of tokens.\n",
    "        \n",
    "    Example:\n",
    "    Input : This is a nice place to live. \n",
    "    Output : ['This', 'is', 'a', 'nice', 'place', 'to', 'live']\n",
    "    \"\"\"\n",
    "    list_of_tweets = []\n",
    "    # For each article in Processed_Content\n",
    "    for tweet in Data:\n",
    "        # split each article into tokens of words either alpha or numeric (not a single punctuation)\n",
    "        tokens = re.findall(\"[\\w']+\", tweet) # [\\w]+ --> Checks for more than one occurrence of words which are either alpha or numeric.\n",
    "        # Appending each list of tokens for each article.\n",
    "        list_of_tweets.append(tokens)  \n",
    "    # Unlisting list of list elements to only one list having all the tokens for each & every article.\n",
    "    list_of_tokens = [item for items in list_of_tweets for item in items]\n",
    "    return list_of_tokens\n",
    "list_of_tokens = list_tokens(data)\n",
    "print(len(list_of_tokens))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Running Noise Removal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "en_stopwords = [\"i\", \"me\", \"my\", \"myself\", \"we\", \"our\", \"ours\", \"ourselves\", \"you\", \"your\", \"yours\", \"yourself\", \"yourselves\", \"he\", \"him\", \"his\", \"himself\", \"she\", \"her\", \"hers\", \"herself\", \"it\", \"its\", \"itself\", \"they\", \"them\", \"their\", \"theirs\", \"themselves\", \"what\", \"which\", \"who\", \"whom\", \"this\", \"that\", \"these\", \"those\", \"am\", \"is\", \"are\", \"was\", \"were\", \"be\", \"been\", \"being\", \"have\", \"has\", \"had\", \"having\", \"do\", \"does\", \"did\", \"doing\", \"a\", \"an\", \"the\", \"and\", \"but\", \"if\", \"or\", \"because\", \"as\", \"until\", \"while\", \"of\", \"at\", \"by\", \"for\", \"with\", \"about\", \"against\", \"between\", \"into\", \"through\", \"during\", \"before\", \"after\", \"above\", \"below\", \"to\", \"from\", \"up\", \"down\", \"in\", \"out\", \"on\", \"off\", \"over\", \"under\", \"again\", \"further\", \"then\", \"once\", \"here\", \"there\", \"when\", \"where\", \"why\", \"how\", \"all\", \"any\", \"both\", \"each\", \"few\", \"more\", \"most\", \"other\", \"some\", \"such\", \"no\", \"nor\", \"not\", \"only\", \"own\", \"same\", \"so\", \"than\", \"too\", \"very\", \"s\", \"t\", \"can\", \"will\", \"just\", \"don\", \"should\", \"now\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokens = []\n",
    "for item in list_of_tokens:\n",
    "    tokens.append(item.lower())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "322670\n"
     ]
    }
   ],
   "source": [
    "tokens_filtered = []\n",
    "for item in tokens:\n",
    "    if item not in en_stopwords:\n",
    "        tokens_filtered.append(item)\n",
    "\n",
    "print(len(tokens_filtered))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "removing tokens that do not register as words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(tokens_filtered))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(tokens_filtered).to_csv('tokens_filtered.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "#get list from csv so I don't have to refilter\n",
    "f = (location + \"\\\\tokens_filtered.csv\")\n",
    "df = pd.read_csv(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "33558\n"
     ]
    }
   ],
   "source": [
    "tokens_filtered = df['0'].tolist()\n",
    "tokens_filtered = set(tokens_filtered)\n",
    "tokens_filtered = list(tokens_filtered)\n",
    "print(len(tokens_filtered))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 21027/21027 [14:58<00:00, 23.39it/s]\n"
     ]
    }
   ],
   "source": [
    "#finding how often each token appears\n",
    "from tqdm import tqdm\n",
    "tweets = data\n",
    "data = None\n",
    "\n",
    "token_frequency = {}\n",
    "\n",
    "for word in tokens_filtered:\n",
    "    token_frequency[word] = 0\n",
    "\n",
    "for i in tqdm(range(len(tweets))):\n",
    "    tweet = tweets[i]\n",
    "    for word in tokens_filtered:\n",
    "        current = int(token_frequency[word])\n",
    "        new = current + tweet.count(str(word))\n",
    "        token_frequency[word] = new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>token</th>\n",
       "      <th>frequency</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>14599</th>\n",
       "      <td>e</td>\n",
       "      <td>197808</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9936</th>\n",
       "      <td>o</td>\n",
       "      <td>152807</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16826</th>\n",
       "      <td>n</td>\n",
       "      <td>134944</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28793</th>\n",
       "      <td>r</td>\n",
       "      <td>113166</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24480</th>\n",
       "      <td>l</td>\n",
       "      <td>83102</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13510</th>\n",
       "      <td>uiepeaor9w</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13509</th>\n",
       "      <td>yhyqrrowqf</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13508</th>\n",
       "      <td>dmsqxxemw8</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13507</th>\n",
       "      <td>kwyzmrhgmk</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33557</th>\n",
       "      <td>ytlxezz6v2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>33558 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            token  frequency\n",
       "14599           e     197808\n",
       "9936            o     152807\n",
       "16826           n     134944\n",
       "28793           r     113166\n",
       "24480           l      83102\n",
       "...           ...        ...\n",
       "13510  uiepeaor9w          0\n",
       "13509  yhyqrrowqf          0\n",
       "13508  dmsqxxemw8          0\n",
       "13507  kwyzmrhgmk          0\n",
       "33557  ytlxezz6v2          0\n",
       "\n",
       "[33558 rows x 2 columns]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "token_freq_list = []\n",
    "for word in tokens_filtered:\n",
    "    token_freq_list.append({\"token\": word, \"frequency\": token_frequency[word]})\n",
    "    \n",
    "pd.DataFrame(token_freq_list).sort_values(by=['frequency'], ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2947\n"
     ]
    }
   ],
   "source": [
    "from english_words import english_words_set\n",
    "\n",
    "df = []\n",
    "for item in token_freq_list:\n",
    "    if len(str(item[\"token\"])) >= 5:\n",
    "        #check if token is word\n",
    "        if item[\"token\"] in english_words_set:\n",
    "            df.append(item)\n",
    "token_freq_list = df\n",
    "print(len(token_freq_list))\n",
    "token_freq_list = pd.DataFrame(token_freq_list).sort_values(by=['frequency'], ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>token</th>\n",
       "      <th>frequency</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1177</th>\n",
       "      <td>sexual</td>\n",
       "      <td>10429</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>546</th>\n",
       "      <td>assault</td>\n",
       "      <td>8204</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>183</th>\n",
       "      <td>student</td>\n",
       "      <td>3723</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1713</th>\n",
       "      <td>harass</td>\n",
       "      <td>1759</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2562</th>\n",
       "      <td>convict</td>\n",
       "      <td>1475</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2670</th>\n",
       "      <td>campus</td>\n",
       "      <td>1305</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1062</th>\n",
       "      <td>school</td>\n",
       "      <td>1244</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2348</th>\n",
       "      <td>month</td>\n",
       "      <td>1244</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1853</th>\n",
       "      <td>conduct</td>\n",
       "      <td>1240</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1806</th>\n",
       "      <td>story</td>\n",
       "      <td>1083</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2129</th>\n",
       "      <td>minute</td>\n",
       "      <td>1035</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1389</th>\n",
       "      <td>charge</td>\n",
       "      <td>1005</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1020</th>\n",
       "      <td>father</td>\n",
       "      <td>984</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>631</th>\n",
       "      <td>defend</td>\n",
       "      <td>971</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1536</th>\n",
       "      <td>victim</td>\n",
       "      <td>969</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1962</th>\n",
       "      <td>invest</td>\n",
       "      <td>897</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1822</th>\n",
       "      <td>start</td>\n",
       "      <td>891</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2724</th>\n",
       "      <td>light</td>\n",
       "      <td>887</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1281</th>\n",
       "      <td>woman</td>\n",
       "      <td>817</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2924</th>\n",
       "      <td>history</td>\n",
       "      <td>791</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2555</th>\n",
       "      <td>accuse</td>\n",
       "      <td>767</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2260</th>\n",
       "      <td>sentence</td>\n",
       "      <td>756</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1940</th>\n",
       "      <td>football</td>\n",
       "      <td>711</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1872</th>\n",
       "      <td>women</td>\n",
       "      <td>658</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2447</th>\n",
       "      <td>event</td>\n",
       "      <td>492</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>judge</td>\n",
       "      <td>460</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1769</th>\n",
       "      <td>abuse</td>\n",
       "      <td>439</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2769</th>\n",
       "      <td>allege</td>\n",
       "      <td>422</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>886</th>\n",
       "      <td>thing</td>\n",
       "      <td>419</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>282</th>\n",
       "      <td>police</td>\n",
       "      <td>409</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         token  frequency\n",
       "1177    sexual      10429\n",
       "546    assault       8204\n",
       "183    student       3723\n",
       "1713    harass       1759\n",
       "2562   convict       1475\n",
       "2670    campus       1305\n",
       "1062    school       1244\n",
       "2348     month       1244\n",
       "1853   conduct       1240\n",
       "1806     story       1083\n",
       "2129    minute       1035\n",
       "1389    charge       1005\n",
       "1020    father        984\n",
       "631     defend        971\n",
       "1536    victim        969\n",
       "1962    invest        897\n",
       "1822     start        891\n",
       "2724     light        887\n",
       "1281     woman        817\n",
       "2924   history        791\n",
       "2555    accuse        767\n",
       "2260  sentence        756\n",
       "1940  football        711\n",
       "1872     women        658\n",
       "2447     event        492\n",
       "21       judge        460\n",
       "1769     abuse        439\n",
       "2769    allege        422\n",
       "886      thing        419\n",
       "282     police        409"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "token_freq_list.head(30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(token_freq_list).to_csv('tokens_filtered_freq.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2946\n"
     ]
    }
   ],
   "source": [
    "#Import from csv to list of dicts\n",
    "f = (location + \"\\\\tokens_filtered_freq.csv\")\n",
    "df = pd.read_csv(f)\n",
    "\n",
    "token_freq_list = []\n",
    "for item in (df.values.tolist()[1:]):\n",
    "    token_freq_list.append({\"token\": item[1], \"frequency\": item[2]})\n",
    "print(len(token_freq_list))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
