{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "location = str(os.getcwd())\n",
    "root = location[:-15]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Comparing gnews and custom model results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11768\n"
     ]
    }
   ],
   "source": [
    "f = (root + \"Articles\\\\articles_cleaned.csv\")\n",
    "articles = pd.read_csv(f)\n",
    "articles = articles.to_dict(\"index\")\n",
    "print(len(articles))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9856\n"
     ]
    }
   ],
   "source": [
    "#import custom model clustering results\n",
    "f = (root + \"Analyses\\\\KMeans\\\\Results\\\\articles_kmeans_clusters_custom.csv\")\n",
    "custom = pd.read_csv(f)\n",
    "custom = custom.to_dict(\"index\")\n",
    "print(len(custom))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9856\n"
     ]
    }
   ],
   "source": [
    "#import google news model clustering results\n",
    "f = (root + \"Analyses\\\\KMeans\\\\Results\\\\articles_kmeans_clusters_gnews.csv\")\n",
    "gnews = pd.read_csv(f)\n",
    "gnews = gnews.to_dict(\"index\")\n",
    "print(len(gnews))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1780\n"
     ]
    }
   ],
   "source": [
    "#gathering tokens\n",
    "comp_list = []\n",
    "for i in range(len(gnews)):\n",
    "    if gnews[i][\"frequency\"] >= 200:\n",
    "        token = gnews[i][\"token\"]\n",
    "        gnews_cluster = gnews[i][\"cluster\"]\n",
    "        comp_list.append({\"token\": token, \"gnews_cluster\": gnews_cluster})\n",
    "print(len(comp_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1780/1780 [00:02<00:00, 674.40it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1779\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "x = 0\n",
    "\n",
    "for i in tqdm(range(len(comp_list))):\n",
    "    for j in range(len(custom)):\n",
    "        if comp_list[i][\"token\"] == custom[j][\"token\"]:\n",
    "            comp_list[i][\"custom_cluster\"] = custom[j][\"cluster\"]\n",
    "            x += 1\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "for item in comp_list:\n",
    "    if item[\"token\"] == \"false\":\n",
    "        comp_list.remove(item)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "for item in comp_list:\n",
    "    if item[\"gnews_cluster\"] == 0:\n",
    "        item[\"gnews_cluster\"] = 1\n",
    "    elif item[\"gnews_cluster\"] == 1:\n",
    "        item[\"gnews_cluster\"] = 2\n",
    "    elif item[\"gnews_cluster\"] == 2:\n",
    "        item[\"gnews_cluster\"] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "902\n",
      "877\n"
     ]
    }
   ],
   "source": [
    "x = 0\n",
    "y = 0\n",
    "\n",
    "matches = []\n",
    "non_matches = []\n",
    "for item in comp_list:\n",
    "    try:\n",
    "        if item[\"gnews_cluster\"] == item[\"custom_cluster\"]:\n",
    "            x += 1\n",
    "            matches.append(item)\n",
    "        else:\n",
    "            y += 1\n",
    "            non_matches.append(item)\n",
    "    except:\n",
    "        (print(item))\n",
    "print(x)\n",
    "print(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "number of matches chagnes depending on arbitrary cluster label assignment, so I am going with the label assignments that yields the highest number of matches\n",
    "\n",
    "594 matches\n",
    "1185 non-matches\n",
    "\n",
    "283 matches\n",
    "1496 non-matches\n",
    "\n",
    "902 matches\n",
    "877 non-matches\n",
    "(winner winner)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "source": [
    "need to check to see if matches between models largely line up with meaningful tokens from hand-sorting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "765\n"
     ]
    }
   ],
   "source": [
    "f = (root + \"Analyses\\\\KMeans\\\\Results\\\\meaningful_terms.csv\")\n",
    "meaningful_terms = pd.read_csv(f)\n",
    "meaningful_terms = meaningful_terms.to_dict(\"index\")\n",
    "print(len(meaningful_terms))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "214\n",
      "551\n"
     ]
    }
   ],
   "source": [
    "x = 0\n",
    "y = 0\n",
    "\n",
    "matches = []\n",
    "non_matches = []\n",
    "terms = []\n",
    "for i in range(len(meaningful_terms)):\n",
    "    terms.append(meaningful_terms[i][\"token\"])\n",
    "\n",
    "for item in comp_list:\n",
    "    if item[\"token\"] in terms:\n",
    "        try:\n",
    "            if item[\"gnews_cluster\"] == item[\"custom_cluster\"]:\n",
    "                x += 1\n",
    "                matches.append(item)\n",
    "            else:\n",
    "                y += 1\n",
    "                non_matches.append(item)\n",
    "        except:\n",
    "            (print(item))\n",
    "print(x)\n",
    "print(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "143 matches\n",
    "622 non-matches\n",
    "\n",
    "408 matches\n",
    "357 non-matches\n",
    "\n",
    "214 matches\n",
    "551 non-matches"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "========================\n",
    "\n",
    "checking to see how many articles fall nicely into one of the three clusters for both models to determine best fit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "gcluster0 = []\n",
    "gcluster1 = []\n",
    "gcluster2 = []\n",
    "\n",
    "for i in range(len(gnews)):\n",
    "    item = gnews[i]\n",
    "    if item[\"cluster\"] == 0:\n",
    "        gcluster0.append(item[\"token\"])\n",
    "    if item[\"cluster\"] == 1:\n",
    "        gcluster1.append(item[\"token\"])\n",
    "    if item[\"cluster\"] == 2:\n",
    "        gcluster2.append(item[\"token\"])\n",
    "    \n",
    "    \n",
    "\n",
    "ccluster0 = []\n",
    "ccluster1 = []\n",
    "ccluster2 = []\n",
    "for i in range(len(custom)):\n",
    "    item = custom[i]\n",
    "    if item[\"cluster\"] == 0:\n",
    "        ccluster0.append(item[\"token\"])\n",
    "    if item[\"cluster\"] == 1:\n",
    "        ccluster1.append(item[\"token\"])\n",
    "    if item[\"cluster\"] == 2:\n",
    "        ccluster2.append(item[\"token\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#list of dicts for saving results\n",
    "results = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7043425324675324\n",
      "0.1444805194805195\n",
      "0.15117694805194806\n"
     ]
    }
   ],
   "source": [
    "total = len(ccluster0) + len(ccluster1) + len(ccluster2)\n",
    "constant0 = len(ccluster0)/total\n",
    "constant1 = len(ccluster1)/total\n",
    "constant2 = len(ccluster2)/total\n",
    "\n",
    "print(constant0)\n",
    "print(constant1)\n",
    "print(constant2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 11768/11768 [10:14<00:00, 19.16it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fits: 10448\n",
      "Non-Fits: 819\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "#checking custom model fit\n",
    "x = -1\n",
    "fuck_ups = []\n",
    "fits = []\n",
    "non_fits = []\n",
    "for i in tqdm(range(len(articles))):\n",
    "    results.append(articles[i])\n",
    "    x += 1\n",
    "    body = articles[i][\"body\"]\n",
    "    body = str(body).split(\" \")\n",
    "    score0 = 0\n",
    "    score1 = 0\n",
    "    score2 = 0\n",
    "    if len(body) > 1 and \"multimedia\" not in articles[i][\"url\"]:\n",
    "        for word in body:\n",
    "            if word in ccluster0:\n",
    "                score0 += 1\n",
    "            elif word in ccluster1:\n",
    "                score1 += 1\n",
    "            elif word in ccluster2:\n",
    "                score2 += 1\n",
    "\n",
    "        score0 = score0/constant0\n",
    "        score1 = score1/constant1\n",
    "        score2 = score2/constant2\n",
    "\n",
    "        total = score0 + score1 + score2\n",
    "        try:\n",
    "            portion0 = score0/total\n",
    "            portion1 = score1/total\n",
    "            portion2 = score2/total\n",
    "            \n",
    "            if portion0 > 0.5 or portion1 > 0.5 or portion2 > 0.5:\n",
    "                fits.append(x)\n",
    "            else:\n",
    "                non_fits.append(x)\n",
    "        except:\n",
    "            fuck_ups.append(x)\n",
    "    else:\n",
    "        fuck_ups.append(x)\n",
    "    results[i][\"size_control_portion_cluster0_custom\"] = portion0\n",
    "    results[i][\"size_control_portion_cluster1_custom\"] = portion1\n",
    "    results[i][\"size_control_portion_cluster2_custom\"] = portion2\n",
    "\n",
    "print(\"Fits: \" + str(len(fits)))\n",
    "print(\"Non-Fits: \" + str(len(non_fits)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.42664366883116883\n",
      "0.012581168831168832\n",
      "0.5607751623376623\n"
     ]
    }
   ],
   "source": [
    "total = len(gcluster0) + len(gcluster1) + len(gcluster2)\n",
    "constant0 = len(gcluster0)/total\n",
    "constant1 = len(gcluster1)/total\n",
    "constant2 = len(gcluster2)/total\n",
    "\n",
    "print(constant0)\n",
    "print(constant1)\n",
    "print(constant2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 11768/11768 [10:10<00:00, 19.28it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fits: 10003\n",
      "Non-Fits: 1264\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "#checking google news model fit\n",
    "x = -1\n",
    "fuck_ups = []\n",
    "fits = []\n",
    "non_fits = []\n",
    "for i in tqdm(range(len(articles))):\n",
    "    x += 1\n",
    "    body = articles[i][\"body\"]\n",
    "    body = str(body).split(\" \")\n",
    "    score0 = 0\n",
    "    score1 = 0\n",
    "    score2 = 0\n",
    "    if len(body) > 1 and \"multimedia\" not in articles[i][\"url\"]:\n",
    "        for word in body:\n",
    "            if word in gcluster0:\n",
    "                score0 += 1\n",
    "            elif word in gcluster1:\n",
    "                score1 += 1\n",
    "            elif word in gcluster2:\n",
    "                score2 += 1\n",
    "\n",
    "        score0 = score0/constant0\n",
    "        score1 = score1/constant1\n",
    "        score2 = score2/constant2\n",
    "\n",
    "        total = score0 + score1 + score2\n",
    "        try:\n",
    "            portion0 = score0/total\n",
    "            portion1 = score1/total\n",
    "            portion2 = score2/total\n",
    "            \n",
    "            if portion0 > 0.5 or portion1 > 0.5 or portion2 > 0.5:\n",
    "                fits.append(x)\n",
    "            else:\n",
    "                non_fits.append(x)\n",
    "        except:\n",
    "            fuck_ups.append(x)\n",
    "    else:\n",
    "        fuck_ups.append(x)\n",
    "    results[i][\"size_control_portion_cluster0_gnews\"] = portion0\n",
    "    results[i][\"size_control_portion_cluster1_gnews\"] = portion1\n",
    "    results[i][\"size_control_portion_cluster2_gnews\"] = portion2\n",
    "\n",
    "print(\"Fits: \" + str(len(fits)))\n",
    "print(\"Non-Fits: \" + str(len(non_fits)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 11768/11768 [10:21<00:00, 18.93it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fits: 8213\n",
      "Non-Fits: 3054\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "#Custom model without use of constant\n",
    "x = -1\n",
    "fuck_ups = []\n",
    "fits = []\n",
    "non_fits = []\n",
    "for i in tqdm(range(len(articles))):\n",
    "    x += 1\n",
    "    body = articles[i][\"body\"]\n",
    "    body = str(body).split(\" \")\n",
    "    score0 = 0\n",
    "    score1 = 0\n",
    "    score2 = 0\n",
    "    if len(body) > 1 and \"multimedia\" not in articles[i][\"url\"]:\n",
    "        for word in body:\n",
    "            if word in ccluster0:\n",
    "                score0 += 1\n",
    "            elif word in ccluster1:\n",
    "                score1 += 1\n",
    "            elif word in ccluster2:\n",
    "                score2 += 1\n",
    "\n",
    "        total = score0 + score1 + score2\n",
    "        try:\n",
    "            portion0 = score0/total\n",
    "            portion1 = score1/total\n",
    "            portion2 = score2/total\n",
    "            \n",
    "            if portion0 > 0.5 or portion1 > 0.5 or portion2 > 0.5:\n",
    "                fits.append(x)\n",
    "            else:\n",
    "                non_fits.append(x)\n",
    "        except:\n",
    "            fuck_ups.append(x)\n",
    "    else:\n",
    "        fuck_ups.append(x)\n",
    "    results[i][\"size_NOcontrol_cluster0_custom\"] = portion0\n",
    "    results[i][\"size_NOcontrol_cluster1_custom\"] = portion1\n",
    "    results[i][\"size_NOcontrol_cluster2_custom\"] = portion2\n",
    "\n",
    "print(\"Fits: \" + str(len(fits)))\n",
    "print(\"Non-Fits: \" + str(len(non_fits)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 11768/11768 [10:11<00:00, 19.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fits: 10850\n",
      "Non-Fits: 417\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "#Google News model without use of constant\n",
    "x = -1\n",
    "fuck_ups = []\n",
    "fits = []\n",
    "non_fits = []\n",
    "for i in tqdm(range(len(articles))):\n",
    "    x += 1\n",
    "    body = articles[i][\"body\"]\n",
    "    body = str(body).split(\" \")\n",
    "    score0 = 0\n",
    "    score1 = 0\n",
    "    score2 = 0\n",
    "    if len(body) > 1 and \"multimedia\" not in articles[i][\"url\"]:\n",
    "        for word in body:\n",
    "            if word in gcluster0:\n",
    "                score0 += 1\n",
    "            elif word in gcluster1:\n",
    "                score1 += 1\n",
    "            elif word in gcluster2:\n",
    "                score2 += 1\n",
    "\n",
    "        total = score0 + score1 + score2\n",
    "        try:\n",
    "            portion0 = score0/total\n",
    "            portion1 = score1/total\n",
    "            portion2 = score2/total\n",
    "            \n",
    "            if portion0 > 0.5 or portion1 > 0.5 or portion2 > 0.5:\n",
    "                fits.append(x)\n",
    "            else:\n",
    "                non_fits.append(x)\n",
    "        except:\n",
    "            fuck_ups.append(x)\n",
    "    else:\n",
    "        fuck_ups.append(x)\n",
    "    results[i][\"size_NOcontrol_cluster0_gnews\"] = portion0\n",
    "    results[i][\"size_NOcontrol_cluster1_gnews\"] = portion1\n",
    "    results[i][\"size_NOcontrol_cluster2_gnews\"] = portion2\n",
    "\n",
    "print(\"Fits: \" + str(len(fits)))\n",
    "print(\"Non-Fits: \" + str(len(non_fits)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Same analysis but taking into account average frequency of each cluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gnews cluster 1: 136.43686087990488\n",
      "0.09503979753189924\n",
      "gnews cluster 2: 979.6129032258065\n",
      "0.6823831285899163\n",
      "gnews cluster 3: 319.52632531210423\n",
      "0.22257707387818443\n",
      "custom cluster 1: 116.49697493517718\n",
      "0.09388527034811399\n",
      "custom cluster 2: 345.2738764044944\n",
      "0.2782572787698107\n",
      "custom cluster 3: 779.0731543624161\n",
      "0.6278574508820753\n",
      "======================================\n",
      "0.42664366883116883\n",
      "0.012581168831168832\n",
      "0.5607751623376623\n",
      "0.7043425324675324\n",
      "0.1444805194805195\n",
      "0.15117694805194806\n"
     ]
    }
   ],
   "source": [
    "count0 = 0\n",
    "count1 = 0\n",
    "count2 = 0\n",
    "\n",
    "total0 = 0\n",
    "total1 = 0\n",
    "total2 = 0\n",
    "\n",
    "for i in range(len(gnews)):\n",
    "    entry = gnews[i]\n",
    "    if entry[\"cluster\"] == 0:\n",
    "        count0 += 1\n",
    "        total0 += entry[\"frequency\"]\n",
    "        \n",
    "    elif entry[\"cluster\"] == 1:\n",
    "        count1 += 1\n",
    "        total1 += entry[\"frequency\"]\n",
    "        \n",
    "    elif entry[\"cluster\"] == 2:\n",
    "        count2 += 1\n",
    "        total2 += entry[\"frequency\"]\n",
    "        \n",
    "g_average_freq0 = (total0/count0)\n",
    "g_average_freq1 = (total1/count1)\n",
    "g_average_freq2 = (total2/count2)\n",
    "total = g_average_freq0+g_average_freq1+g_average_freq2\n",
    "g_average_freq0 = (total0/count0)/total\n",
    "g_average_freq1 = (total1/count1)/total\n",
    "g_average_freq2 = (total2/count2)/total\n",
    "        \n",
    "print(\"gnews cluster 1: \" + str(total0/count0))\n",
    "print(g_average_freq0)\n",
    "print(\"gnews cluster 2: \" + str(total1/count1))\n",
    "print(g_average_freq1)\n",
    "print(\"gnews cluster 3: \" + str(total2/count2))\n",
    "print(g_average_freq2)\n",
    "\n",
    "count0 = 0\n",
    "count1 = 0\n",
    "count2 = 0\n",
    "\n",
    "total0 = 0\n",
    "total1 = 0\n",
    "total2 = 0\n",
    "\n",
    "for i in range(len(custom)):\n",
    "    entry = custom[i]\n",
    "    if entry[\"cluster\"] == 0:\n",
    "        count0 += 1\n",
    "        total0 += entry[\"frequency\"]\n",
    "        \n",
    "    elif entry[\"cluster\"] == 1:\n",
    "        count1 += 1\n",
    "        total1 += entry[\"frequency\"]\n",
    "        \n",
    "    elif entry[\"cluster\"] == 2:\n",
    "        count2 += 1\n",
    "        total2 += entry[\"frequency\"]\n",
    "\n",
    "c_average_freq0 = (total0/count0)\n",
    "c_average_freq1 = (total1/count1)\n",
    "c_average_freq2 = (total2/count2)\n",
    "total = c_average_freq0+c_average_freq1+c_average_freq2\n",
    "c_average_freq0 = (total0/count0)/total\n",
    "c_average_freq1 = (total1/count1)/total\n",
    "c_average_freq2 = (total2/count2)/total\n",
    "\n",
    "print(\"custom cluster 1: \" + str(total0/count0))\n",
    "print(c_average_freq0)\n",
    "print(\"custom cluster 2: \" + str(total1/count1))\n",
    "print(c_average_freq1)\n",
    "print(\"custom cluster 3: \" + str(total2/count2))\n",
    "print(c_average_freq2)\n",
    "\n",
    "print(\"======================================\")\n",
    "\n",
    "total = len(ccluster0) + len(ccluster1) + len(ccluster2)\n",
    "gconstant0 = len(gcluster0)/total\n",
    "gconstant1 = len(gcluster1)/total\n",
    "gconstant2 = len(gcluster2)/total\n",
    "\n",
    "print(gconstant0)\n",
    "print(gconstant1)\n",
    "print(gconstant2)\n",
    "\n",
    "\n",
    "total = len(ccluster0) + len(ccluster1) + len(ccluster2)\n",
    "cconstant0 = len(ccluster0)/total\n",
    "cconstant1 = len(ccluster1)/total\n",
    "cconstant2 = len(ccluster2)/total\n",
    "\n",
    "print(cconstant0)\n",
    "print(cconstant1)\n",
    "print(cconstant2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 11768/11768 [10:20<00:00, 18.97it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fits: 6611\n",
      "Non-Fits: 4656\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "#checking custom model fit accounting for size of clusters and relative average frequency\n",
    "x = -1\n",
    "fuck_ups = []\n",
    "fits = []\n",
    "non_fits = []\n",
    "for i in tqdm(range(len(articles))):\n",
    "    x += 1\n",
    "    body = articles[i][\"body\"]\n",
    "    body = str(body).split(\" \")\n",
    "    score0 = 0\n",
    "    score1 = 0\n",
    "    score2 = 0\n",
    "    if len(body) > 1 and \"multimedia\" not in articles[i][\"url\"]:\n",
    "        for word in body:\n",
    "            if word in ccluster0:\n",
    "                score0 += 1\n",
    "            elif word in ccluster1:\n",
    "                score1 += 1\n",
    "            elif word in ccluster2:\n",
    "                score2 += 1\n",
    "\n",
    "        score0 = (score0/cconstant0)/c_average_freq0\n",
    "        score1 = (score1/cconstant1)/c_average_freq1\n",
    "        score2 = (score2/cconstant2)/c_average_freq2\n",
    "\n",
    "        total = score0 + score1 + score2\n",
    "        try:\n",
    "            portion0 = score0/total\n",
    "            portion1 = score1/total\n",
    "            portion2 = score2/total\n",
    "            \n",
    "            if portion0 > 0.5 or portion1 > 0.5 or portion2 > 0.5:\n",
    "                fits.append(x)\n",
    "            else:\n",
    "                non_fits.append(x)\n",
    "        except:\n",
    "            fuck_ups.append(x)\n",
    "    else:\n",
    "        fuck_ups.append(x)\n",
    "    results[i][\"size_control_portion_aveFreq_cluster0_custom\"] = portion0\n",
    "    results[i][\"size_control_portion_aveFreq_cluster1_custom\"] = portion1\n",
    "    results[i][\"size_control_portion_aveFreq_cluster2_custom\"] = portion2\n",
    "\n",
    "print(\"Fits: \" + str(len(fits)))\n",
    "print(\"Non-Fits: \" + str(len(non_fits)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 11768/11768 [10:13<00:00, 19.17it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fits: 5322\n",
      "Non-Fits: 5945\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "#checking google news model fit accounting for size of clusters and relative average frequency\n",
    "x = -1\n",
    "fuck_ups = []\n",
    "fits = []\n",
    "non_fits = []\n",
    "for i in tqdm(range(len(articles))):\n",
    "    x += 1\n",
    "    body = articles[i][\"body\"]\n",
    "    body = str(body).split(\" \")\n",
    "    score0 = 0\n",
    "    score1 = 0\n",
    "    score2 = 0\n",
    "    if len(body) > 1 and \"multimedia\" not in articles[i][\"url\"]:\n",
    "        for word in body:\n",
    "            if word in gcluster0:\n",
    "                score0 += 1\n",
    "            elif word in gcluster1:\n",
    "                score1 += 1\n",
    "            elif word in gcluster2:\n",
    "                score2 += 1\n",
    "\n",
    "        score0 = (score0/gconstant0)/g_average_freq0\n",
    "        score1 = (score1/gconstant1)/g_average_freq1\n",
    "        score2 = (score2/gconstant2)/g_average_freq2\n",
    "\n",
    "        total = score0 + score1 + score2\n",
    "        try:\n",
    "            portion0 = score0/total\n",
    "            portion1 = score1/total\n",
    "            portion2 = score2/total\n",
    "            \n",
    "            if portion0 > 0.5 or portion1 > 0.5 or portion2 > 0.5:\n",
    "                fits.append(x)\n",
    "            else:\n",
    "                non_fits.append(x)\n",
    "        except:\n",
    "            fuck_ups.append(x)\n",
    "    else:\n",
    "        fuck_ups.append(x)\n",
    "    results[i][\"size_control_portion_aveFreq_cluster0_gnews\"] = portion0\n",
    "    results[i][\"size_control_portion_aveFreq_cluster1_gnews\"] = portion1\n",
    "    results[i][\"size_control_portion_aveFreq_cluster2_gnews\"] = portion2\n",
    "\n",
    "print(\"Fits: \" + str(len(fits)))\n",
    "print(\"Non-Fits: \" + str(len(non_fits)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(results).to_csv('comparing_models.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
