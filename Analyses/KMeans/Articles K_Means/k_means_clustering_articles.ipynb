{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "location = str(os.getcwd())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "45982\n"
     ]
    }
   ],
   "source": [
    "f = (location[:-29] + \"Articles\\\\articles_cleaned.csv\")\n",
    "df = pd.read_csv(f)\n",
    "df = df.to_dict(\"index\")\n",
    "print(len(df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "21027\n"
     ]
    }
   ],
   "source": [
    "#cleaning body text\n",
    "data = []\n",
    "\n",
    "for i in range(len(df)):\n",
    "    text_clean = \"\"\n",
    "#rewrite THIS\n",
    "    if text_clean not in data:\n",
    "        data.append(text_clean)\n",
    "print(len(data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 21027/21027 [00:00<00:00, 30074.64it/s]\n"
     ]
    }
   ],
   "source": [
    "from english_words import english_words_set\n",
    "\n",
    "tokens = [article.split() for article in data]\n",
    "tokens_filtered = []\n",
    "en_stopwords = [\"i\", \"me\", \"my\", \"myself\", \"we\", \"our\", \"ours\", \"ourselves\", \"you\", \"your\", \"yours\", \"yourself\", \"yourselves\", \"he\", \"him\", \"his\", \"himself\", \"she\", \"her\", \"hers\", \"herself\", \"it\", \"its\", \"itself\", \"they\", \"them\", \"their\", \"theirs\", \"themselves\", \"what\", \"which\", \"who\", \"whom\", \"this\", \"that\", \"these\", \"those\", \"am\", \"is\", \"are\", \"was\", \"were\", \"be\", \"been\", \"being\", \"have\", \"has\", \"had\", \"having\", \"do\", \"does\", \"did\", \"doing\", \"a\", \"an\", \"the\", \"and\", \"but\", \"if\", \"or\", \"because\", \"as\", \"until\", \"while\", \"of\", \"at\", \"by\", \"for\", \"with\", \"about\", \"against\", \"between\", \"into\", \"through\", \"during\", \"before\", \"after\", \"above\", \"below\", \"to\", \"from\", \"up\", \"down\", \"in\", \"out\", \"on\", \"off\", \"over\", \"under\", \"again\", \"further\", \"then\", \"once\", \"here\", \"there\", \"when\", \"where\", \"why\", \"how\", \"all\", \"any\", \"both\", \"each\", \"few\", \"more\", \"most\", \"other\", \"some\", \"such\", \"no\", \"nor\", \"not\", \"only\", \"own\", \"same\", \"so\", \"than\", \"too\", \"very\", \"s\", \"t\", \"can\", \"will\", \"just\", \"don\", \"should\", \"now\"]\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "for i in tqdm(range(len(tokens))):\n",
    "    article = tokens[i]\n",
    "    article_filtered = []\n",
    "    for word in tweet:\n",
    "        if word not in en_stopwords:\n",
    "            if word in english_words_set:\n",
    "                tweet_filtered.append(word)\n",
    "    tokens_filtered.append(tweet_filtered)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models import Word2Vec\n",
    "model = Word2Vec(tokens_filtered, min_count=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "showing info https://raw.githubusercontent.com/nltk/nltk_data/gh-pages/index.xml\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gensim.downloader as api\n",
    "import gensim\n",
    "gmodel = api.load(\"google-news-300\")\n",
    "\n",
    "from nltk.cluster import KMeansClusterer\n",
    "import nltk\n",
    "import numpy as np\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(‘%d/%d’ % (i, len(i)), end=‘\\r’)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14625\n",
      "14625\n"
     ]
    }
   ],
   "source": [
    "terms = model.wv.key_to_index\n",
    "gterms = gmodel.key_to_index\n",
    "use_terms = [word for word in terms if word in gterms]\n",
    "\n",
    "\n",
    "T = model.wv[use_terms]\n",
    "G = gmodel[use_terms]\n",
    "print(len(T))\n",
    "print(len(G))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  5%|██████                                                                                                                    | 1/20 [00:00<00:07,  2.43it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "for k=1 the sum of squares is:7649.4680263508635\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|████████████▏                                                                                                             | 2/20 [00:06<00:37,  2.06s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "for k=2 the sum of squares is:8052.3121781040545\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 15%|██████████████████▎                                                                                                       | 3/20 [00:17<01:19,  4.65s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "for k=3 the sum of squares is:8279.92893437596\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|████████████████████████▍                                                                                                 | 4/20 [00:33<02:11,  8.21s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "for k=4 the sum of squares is:8466.770036922107\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 25%|██████████████████████████████▌                                                                                           | 5/20 [00:51<02:45, 11.01s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "for k=5 the sum of squares is:8581.415972204497\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 30%|████████████████████████████████████▌                                                                                     | 6/20 [01:43<05:27, 23.40s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "for k=6 the sum of squares is:8808.747451652647\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 35%|██████████████████████████████████████████▋                                                                               | 7/20 [02:03<04:52, 22.50s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "for k=7 the sum of squares is:8877.003994584953\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|████████████████████████████████████████████████▊                                                                         | 8/20 [02:40<05:20, 26.72s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "for k=8 the sum of squares is:8874.506681092602\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 45%|██████████████████████████████████████████████████████▉                                                                   | 9/20 [03:13<05:14, 28.60s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "for k=9 the sum of squares is:8983.595677898627\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|████████████████████████████████████████████████████████████▌                                                            | 10/20 [04:02<05:46, 34.65s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "for k=10 the sum of squares is:9127.416303099535\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 55%|██████████████████████████████████████████████████████████████████▌                                                      | 11/20 [05:24<07:19, 48.87s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "for k=11 the sum of squares is:9094.153713660737\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|████████████████████████████████████████████████████████████████████████▌                                                | 12/20 [06:52<08:06, 60.81s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "for k=12 the sum of squares is:9140.291975017057\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 65%|██████████████████████████████████████████████████████████████████████████████▋                                          | 13/20 [07:36<06:29, 55.65s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "for k=13 the sum of squares is:9226.947424942293\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 70%|████████████████████████████████████████████████████████████████████████████████████▋                                    | 14/20 [08:09<04:52, 48.81s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "for k=14 the sum of squares is:9261.518113397273\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 75%|██████████████████████████████████████████████████████████████████████████████████████████▊                              | 15/20 [09:16<04:31, 54.24s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "for k=15 the sum of squares is:9342.699940120712\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80%|████████████████████████████████████████████████████████████████████████████████████████████████▊                        | 16/20 [10:17<03:45, 56.42s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "for k=16 the sum of squares is:9384.151557690604\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 85%|██████████████████████████████████████████████████████████████████████████████████████████████████████▊                  | 17/20 [11:02<02:38, 52.99s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "for k=17 the sum of squares is:9372.130941730707\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 90%|████████████████████████████████████████████████████████████████████████████████████████████████████████████▉            | 18/20 [11:56<01:46, 53.31s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "for k=18 the sum of squares is:9430.777667333032\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 95%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████▉      | 19/20 [13:15<01:01, 61.05s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "for k=19 the sum of squares is:9455.850768077387\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 20/20 [14:41<00:00, 44.05s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "for k=20 the sum of squares is:9491.94623730146\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[7649.4680263508635,\n",
       " 8052.3121781040545,\n",
       " 8279.92893437596,\n",
       " 8466.770036922107,\n",
       " 8581.415972204497,\n",
       " 8808.747451652647,\n",
       " 8877.003994584953,\n",
       " 8874.506681092602,\n",
       " 8983.595677898627,\n",
       " 9127.416303099535,\n",
       " 9094.153713660737,\n",
       " 9140.291975017057,\n",
       " 9226.947424942293,\n",
       " 9261.518113397273,\n",
       " 9342.699940120712,\n",
       " 9384.151557690604,\n",
       " 9372.130941730707,\n",
       " 9430.777667333032,\n",
       " 9455.850768077387,\n",
       " 9491.94623730146]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#checking number of clusters with wss\n",
    "\n",
    "#custom model\n",
    "sum_of_square_values = []\n",
    "for k in tqdm(range(1,21)):\n",
    "    kclusterer = KMeansClusterer(k, distance=nltk.cluster.util.cosine_distance)\n",
    "    assigned_clusters = kclusterer.cluster(T, assign_clusters=True)\n",
    "\n",
    "    sum_of_squares = 0\n",
    "    current_cluster = 0\n",
    "    for centroid in kclusterer.means():\n",
    "        current_page = 0\n",
    "        for index_of_cluster_of_page in assigned_clusters:\n",
    "            if index_of_cluster_of_page == current_cluster:\n",
    "                y = T[current_page]\n",
    "                sum_of_squares += (np.dot(centroid,y)**2)/(np.dot(centroid,centroid) * np.dot(y,y))\n",
    "            current_page += 1\n",
    "        current_cluster += 1\n",
    "    sum_of_square_values.append(sum_of_squares)\n",
    "\n",
    "#google model\n",
    "gsum_of_square_values = []\n",
    "for k in tqdm(range(1,21)):\n",
    "    kclusterer = KMeansClusterer(k, distance=nltk.cluster.util.cosine_distance)\n",
    "    assigned_clusters = kclusterer.cluster(G, assign_clusters=True)\n",
    "\n",
    "    sum_of_squares = 0\n",
    "    current_cluster = 0\n",
    "    for centroid in kclusterer.means():\n",
    "        current_page = 0\n",
    "        for index_of_cluster_of_page in assigned_clusters:\n",
    "            if index_of_cluster_of_page == current_cluster:\n",
    "                y = G[current_page]\n",
    "                sum_of_squares += (np.dot(centroid,y)**2)/(np.dot(centroid,centroid) * np.dot(y,y))\n",
    "            current_page += 1\n",
    "        current_cluster += 1\n",
    "    gsum_of_square_values.append(sum_of_squares)\n",
    "    \n",
    "print(sum_of_square_values)\n",
    "print(gsum_of_square_values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 20/20 [09:07<00:00, 27.38s/it]\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 20/20 [07:38<00:00, 22.95s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1.3818723503921926, 1.3230707463690499, 1.160777385497667, 1.127530934748275, 1.1097885676229928, 1.0816233796562393, 1.0712537155780608, 1.0612657653071584, 1.0502491944079542, 1.0437309817714397, 1.0303826728128485, 1.0209542996268537, 1.0135153232955758, 1.0063790883436299, 1.0079600150110013, 0.9847645899185425, 0.983939113515407, 0.9758949738318188, 0.9718707517124919, 0.9620019363638453]\n",
      "[3.0379713360664553, 3.0170742255780856, 2.9801884845949043, 2.961491589434526, 2.9472396914592554, 2.9268935978546744, 2.927842481065104, 2.9084443192121374, 2.9132238202398453, 2.9070917848259747, 2.9059254002771073, 2.8799674275734604, 2.8756945973247694, 2.875552147043596, 2.8650273537577755, 2.860946899827552, 2.855750244047214, 2.8530527157471117, 2.8465325259370124, 2.846556450925078]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "#checking number of clusters using distortion\n",
    "from scipy.spatial.distance import cdist\n",
    "\n",
    "#custom model\n",
    "distortions = []\n",
    "for k in tqdm(range(1,21)):\n",
    "    kclusterer = KMeansClusterer(k, distance=nltk.cluster.util.euclidean_distance)\n",
    "    assigned_clusters = kclusterer.cluster(T, assign_clusters=True)\n",
    "    distortions.append(sum(np.min(cdist(T, kclusterer.means()), axis=1))/ T.shape[0])\n",
    "\n",
    "#google news model\n",
    "gdistortions = []\n",
    "for k in tqdm(range(1,21)):\n",
    "    kclusterer = KMeansClusterer(k, distance=nltk.cluster.util.euclidean_distance)\n",
    "    assigned_clusters = kclusterer.cluster(G, assign_clusters=True)\n",
    "    gdistortions.append(sum(np.min(cdist(G, kclusterer.means()), axis=1))/ G.shape[0])\n",
    "\n",
    "print(distortions)\n",
    "print(gdistortions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creating Clusters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-10-da77dadb5d1a>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mNUM_CLUSTERS\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m3\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[0mkclusterer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mKMeansClusterer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mNUM_CLUSTERS\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdistance\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mnltk\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcluster\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mutil\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcosine_distance\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrepeats\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m25\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[0massigned_clusters\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mkclusterer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcluster\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mT\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0massign_clusters\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mc:\\users\\wil\\desktop\\getoldtweets\\lib\\site-packages\\nltk\\cluster\\util.py\u001b[0m in \u001b[0;36mcluster\u001b[1;34m(self, vectors, assign_clusters, trace)\u001b[0m\n\u001b[0;32m     58\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     59\u001b[0m         \u001b[1;31m# call abstract method to cluster the vectors\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 60\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcluster_vectorspace\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvectors\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrace\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     61\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     62\u001b[0m         \u001b[1;31m# assign the vectors to clusters\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\wil\\desktop\\getoldtweets\\lib\\site-packages\\nltk\\cluster\\kmeans.py\u001b[0m in \u001b[0;36mcluster_vectorspace\u001b[1;34m(self, vectors, trace)\u001b[0m\n\u001b[0;32m     89\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_means\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mtrial\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     90\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_means\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_rng\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msample\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvectors\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_num_means\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 91\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_cluster_vectorspace\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvectors\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrace\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     92\u001b[0m             \u001b[0mmeanss\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_means\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     93\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\wil\\desktop\\getoldtweets\\lib\\site-packages\\nltk\\cluster\\kmeans.py\u001b[0m in \u001b[0;36m_cluster_vectorspace\u001b[1;34m(self, vectors, trace)\u001b[0m\n\u001b[0;32m    120\u001b[0m                 \u001b[0mclusters\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mm\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_num_means\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    121\u001b[0m                 \u001b[1;32mfor\u001b[0m \u001b[0mvector\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mvectors\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 122\u001b[1;33m                     \u001b[0mindex\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mclassify_vectorspace\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvector\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    123\u001b[0m                     \u001b[0mclusters\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mindex\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvector\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    124\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\wil\\desktop\\getoldtweets\\lib\\site-packages\\nltk\\cluster\\kmeans.py\u001b[0m in \u001b[0;36mclassify_vectorspace\u001b[1;34m(self, vector)\u001b[0m\n\u001b[0;32m    145\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mindex\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_means\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    146\u001b[0m             \u001b[0mmean\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_means\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mindex\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 147\u001b[1;33m             \u001b[0mdist\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_distance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvector\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmean\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    148\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mbest_distance\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mdist\u001b[0m \u001b[1;33m<\u001b[0m \u001b[0mbest_distance\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    149\u001b[0m                 \u001b[0mbest_index\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbest_distance\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mindex\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdist\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\wil\\desktop\\getoldtweets\\lib\\site-packages\\nltk\\cluster\\util.py\u001b[0m in \u001b[0;36mcosine_distance\u001b[1;34m(u, v)\u001b[0m\n\u001b[0;32m    129\u001b[0m     \u001b[0mequal\u001b[0m \u001b[0mto\u001b[0m \u001b[1;36m1\u001b[0m \u001b[1;33m-\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mu\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mv\u001b[0m \u001b[1;33m/\u001b[0m \u001b[1;33m|\u001b[0m\u001b[0mu\u001b[0m\u001b[1;33m|\u001b[0m\u001b[1;33m|\u001b[0m\u001b[0mv\u001b[0m\u001b[1;33m|\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    130\u001b[0m     \"\"\"\n\u001b[1;32m--> 131\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[1;36m1\u001b[0m \u001b[1;33m-\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mu\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mv\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m/\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0msqrt\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mu\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mu\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m*\u001b[0m \u001b[0msqrt\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mv\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mv\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    132\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    133\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<__array_function__ internals>\u001b[0m in \u001b[0;36mdot\u001b[1;34m(*args, **kwargs)\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "NUM_CLUSTERS = 3\n",
    "kclusterer = KMeansClusterer(NUM_CLUSTERS, distance=nltk.cluster.util.cosine_distance, repeats=25)\n",
    "assigned_clusters = kclusterer.cluster(T, assign_clusters=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = (location + \"\\\\tokens_filtered_freq.csv\")\n",
    "df = pd.read_csv(f)\n",
    "\n",
    "token_freq_list = []\n",
    "for item in (df.values.tolist()[1:]):\n",
    "    token_freq_list.append({\"token\": item[1], \"frequency\": item[2]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "words = list(model.wv.key_to_index)\n",
    "cutouts = []\n",
    "for word in words:\n",
    "    if word not in gmodel.key_to_index:\n",
    "        cutouts.append(word)\n",
    "\n",
    "for word in cutouts:\n",
    "    words.remove(word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 14625/14625 [00:26<00:00, 554.34it/s]\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "df = []\n",
    "for i in tqdm(range(len(words))):\n",
    "    word = words[i]\n",
    "    cluster = assigned_clusters[i]\n",
    "    for item in token_freq_list:\n",
    "        if word == item[\"token\"]:\n",
    "            df.append({\"token\": word, \"cluster\": cluster, \"frequency\": item[\"frequency\"]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(df).to_csv('articles_kmeans_clusters_custom.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = (location[:-8] + \"Analyses\\\\articles_kmeans_clusters_gnews.csv\")\n",
    "gdf = pd.read_csv(f)\n",
    "gdf = gdf.to_dict(\"index\")\n",
    "gnews_list = []\n",
    "\n",
    "for i in range(len(gdf)):\n",
    "    gnews_list.append(gdf[i])\n",
    "\n",
    "f = (location[:-8] + \"Analyses\\\\articles_kmeans_clusters_custom.csv\")\n",
    "tdf = pd.read_csv(f)\n",
    "tdf = tdf.to_dict(\"index\")\n",
    "custom_list = []\n",
    "\n",
    "for i in range(len(tdf)):\n",
    "    custom_list.append(tdf[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "cluster1 = []\n",
    "cluster2 = []\n",
    "cluster3 = []\n",
    "\n",
    "\n",
    "for entry in gnews_list:\n",
    "    if entry[\"cluster\"] == 0:\n",
    "        cluster1.append({\"token\": entry[\"token\"], \"frequency\": entry[\"frequency\"]})\n",
    "    elif entry[\"cluster\"] == 1:\n",
    "        cluster2.append({\"token\": entry[\"token\"], \"frequency\": entry[\"frequency\"]})\n",
    "    elif entry[\"cluster\"] == 2:\n",
    "        cluster3.append({\"token\": entry[\"token\"], \"frequency\": entry[\"frequency\"]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>token</th>\n",
       "      <th>frequency</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>sexual</td>\n",
       "      <td>30497</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>women</td>\n",
       "      <td>12479</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>victim</td>\n",
       "      <td>9530</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>93</th>\n",
       "      <td>resident</td>\n",
       "      <td>9085</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>person</td>\n",
       "      <td>7547</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>school</td>\n",
       "      <td>7270</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>police</td>\n",
       "      <td>6764</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>story</td>\n",
       "      <td>6005</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>crime</td>\n",
       "      <td>6004</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2208</th>\n",
       "      <td>ether</td>\n",
       "      <td>5396</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>friend</td>\n",
       "      <td>5367</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>633</th>\n",
       "      <td>organ</td>\n",
       "      <td>5323</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>found</td>\n",
       "      <td>5317</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>class</td>\n",
       "      <td>5260</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>college</td>\n",
       "      <td>5223</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>woman</td>\n",
       "      <td>5062</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>night</td>\n",
       "      <td>4988</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>health</td>\n",
       "      <td>4873</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>incident</td>\n",
       "      <td>4783</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>68</th>\n",
       "      <td>search</td>\n",
       "      <td>4657</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>158</th>\n",
       "      <td>trans</td>\n",
       "      <td>4636</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>116</th>\n",
       "      <td>table</td>\n",
       "      <td>4632</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>118</th>\n",
       "      <td>dress</td>\n",
       "      <td>4404</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3954</th>\n",
       "      <td>discus</td>\n",
       "      <td>4398</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>light</td>\n",
       "      <td>4304</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         token  frequency\n",
       "0       sexual      30497\n",
       "1        women      12479\n",
       "8       victim       9530\n",
       "93    resident       9085\n",
       "12      person       7547\n",
       "5       school       7270\n",
       "2       police       6764\n",
       "11       story       6005\n",
       "10       crime       6004\n",
       "2208     ether       5396\n",
       "33      friend       5367\n",
       "633      organ       5323\n",
       "3        found       5317\n",
       "23       class       5260\n",
       "4      college       5223\n",
       "6        woman       5062\n",
       "18       night       4988\n",
       "7       health       4873\n",
       "20    incident       4783\n",
       "68      search       4657\n",
       "158      trans       4636\n",
       "116      table       4632\n",
       "118      dress       4404\n",
       "3954    discus       4398\n",
       "39       light       4304"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(cluster1).sort_values(by=['frequency'], ascending=False).head(25)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
