{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "location = str(os.getcwd())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11768\n"
     ]
    }
   ],
   "source": [
    "f = (location[:-8] + \"Articles\\\\articles_cleaned.csv\")\n",
    "df = pd.read_csv(f)\n",
    "df = df.to_dict(\"index\")\n",
    "print(len(df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11768\n"
     ]
    }
   ],
   "source": [
    "#cleaning body text\n",
    "for i in range(len(df)):\n",
    "    df[i][\"body\"] = str(df[i][\"body\"]).replace(\"\\n\", \"\").replace(\"\\r\", \"\").replace(\".\", \". \")\n",
    "print(len(df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import pandas as pd\n",
    "import nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "articles = []\n",
    "for i in range(len(df)):\n",
    "    articles.append(df[i][\"body\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "from english_words import english_words_set\n",
    "\n",
    "tokens = [article.split() for article in articles]\n",
    "tokens_filtered = []\n",
    "en_stopwords = [\"i\", \"me\", \"my\", \"myself\", \"we\", \"our\", \"ours\", \"ourselves\", \"you\", \"your\", \"yours\", \"yourself\", \"yourselves\", \"he\", \"him\", \"his\", \"himself\", \"she\", \"her\", \"hers\", \"herself\", \"it\", \"its\", \"itself\", \"they\", \"them\", \"their\", \"theirs\", \"themselves\", \"what\", \"which\", \"who\", \"whom\", \"this\", \"that\", \"these\", \"those\", \"am\", \"is\", \"are\", \"was\", \"were\", \"be\", \"been\", \"being\", \"have\", \"has\", \"had\", \"having\", \"do\", \"does\", \"did\", \"doing\", \"a\", \"an\", \"the\", \"and\", \"but\", \"if\", \"or\", \"because\", \"as\", \"until\", \"while\", \"of\", \"at\", \"by\", \"for\", \"with\", \"about\", \"against\", \"between\", \"into\", \"through\", \"during\", \"before\", \"after\", \"above\", \"below\", \"to\", \"from\", \"up\", \"down\", \"in\", \"out\", \"on\", \"off\", \"over\", \"under\", \"again\", \"further\", \"then\", \"once\", \"here\", \"there\", \"when\", \"where\", \"why\", \"how\", \"all\", \"any\", \"both\", \"each\", \"few\", \"more\", \"most\", \"other\", \"some\", \"such\", \"no\", \"nor\", \"not\", \"only\", \"own\", \"same\", \"so\", \"than\", \"too\", \"very\", \"s\", \"t\", \"can\", \"will\", \"just\", \"don\", \"should\", \"now\"]\n",
    "\n",
    "for article in tokens:\n",
    "    article_filtered = []\n",
    "    for word in article:\n",
    "        if word not in en_stopwords:\n",
    "            if word in english_words_set:\n",
    "                article_filtered.append(word)\n",
    "    tokens_filtered.append(article_filtered)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models import Word2Vec\n",
    "model = Word2Vec(tokens_filtered, min_count=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[==================================================] 100.0% 1662.8/1662.8MB downloaded\n"
     ]
    }
   ],
   "source": [
    "import gensim.downloader as api\n",
    "import gensim\n",
    "gmodel = api.load(\"word2vec-google-news-300\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = gmodel[model.wv.key_to_index if word in model.wv.vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22\n",
      "['grey', 'Klux', 'cancelled', 'glamour', 'analyses', 'dreamt', 'axe', 'A&M', 'catalogue', 'cancelling', 'hurrah', 'harshen', 'labour', 'moustache', 'entendre', 'spilt', 'AT&T', 'determinacy', 'expansible', 'formulae', 'doughnut', 'scopic']\n"
     ]
    }
   ],
   "source": [
    "y = []\n",
    "x = 0\n",
    "cutouts = []\n",
    "for item in model.wv.key_to_index:\n",
    "    try:\n",
    "        y.append(gmodel[item])\n",
    "    except:\n",
    "        x += 1\n",
    "        cutouts.append(item)\n",
    "print(x)\n",
    "print(cutouts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.cluster import KMeansClusterer\n",
    "import nltk\n",
    "NUM_CLUSTERS= 4\n",
    "kclusterer = KMeansClusterer(NUM_CLUSTERS, distance=nltk.cluster.util.cosine_distance, repeats=25)\n",
    "assigned_clusters = kclusterer.cluster(y, assign_clusters=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = (location + \"\\\\tokens_filtered_freq.csv\")\n",
    "df = pd.read_csv(f)\n",
    "\n",
    "token_freq_list = []\n",
    "for item in (df.values.tolist()[1:]):\n",
    "    token_freq_list.append({\"token\": item[1], \"frequency\": item[2]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 14625/14625 [00:09<00:00, 1587.84it/s]\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "words = list(model.wv.key_to_index)\n",
    "for item in cutouts:\n",
    "    words.remove(item)\n",
    "df = []\n",
    "for i in tqdm(range(len(words))):\n",
    "    word = words[i]\n",
    "    cluster = assigned_clusters[i]\n",
    "    for item in token_freq_list:\n",
    "        if word == item[\"token\"]:\n",
    "            df.append({\"token\": word, \"cluster\": cluster, \"frequency\": item[\"frequency\"]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(df).to_csv('articles_kmeans_clusters.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [],
   "source": [
    "cluster1 = []\n",
    "cluster2 = []\n",
    "cluster3 = []\n",
    "cluster4 = []\n",
    "\n",
    "\n",
    "for entry in df:\n",
    "    if entry[\"cluster\"] == 0:\n",
    "        cluster1.append({\"token\": entry[\"token\"], \"frequency\": entry[\"frequency\"]})\n",
    "    elif entry[\"cluster\"] == 1:\n",
    "        cluster2.append({\"token\": entry[\"token\"], \"frequency\": entry[\"frequency\"]})\n",
    "    elif entry[\"cluster\"] == 2:\n",
    "        cluster3.append({\"token\": entry[\"token\"], \"frequency\": entry[\"frequency\"]})\n",
    "    elif entry[\"cluster\"] == 3:\n",
    "        cluster4.append({\"token\": entry[\"token\"], \"frequency\": entry[\"frequency\"]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>token</th>\n",
       "      <th>frequency</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>sexual</td>\n",
       "      <td>30497</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>408</th>\n",
       "      <td>rough</td>\n",
       "      <td>11049</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>story</td>\n",
       "      <td>6005</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>crime</td>\n",
       "      <td>6004</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>430</th>\n",
       "      <td>quest</td>\n",
       "      <td>5933</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2159</th>\n",
       "      <td>ether</td>\n",
       "      <td>5396</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>friend</td>\n",
       "      <td>5367</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2090</th>\n",
       "      <td>belie</td>\n",
       "      <td>5095</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>142</th>\n",
       "      <td>trans</td>\n",
       "      <td>4636</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>305</th>\n",
       "      <td>plain</td>\n",
       "      <td>4300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>world</td>\n",
       "      <td>4166</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>media</td>\n",
       "      <td>4058</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>gender</td>\n",
       "      <td>4027</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>culture</td>\n",
       "      <td>3918</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2987</th>\n",
       "      <td>politic</td>\n",
       "      <td>3867</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>mental</td>\n",
       "      <td>3750</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>often</td>\n",
       "      <td>3558</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>social</td>\n",
       "      <td>3256</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>human</td>\n",
       "      <td>3146</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>little</td>\n",
       "      <td>2895</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1593</th>\n",
       "      <td>selves</td>\n",
       "      <td>2731</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>545</th>\n",
       "      <td>persona</td>\n",
       "      <td>2719</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>wrote</td>\n",
       "      <td>2671</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3159</th>\n",
       "      <td>versa</td>\n",
       "      <td>2637</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>professor</td>\n",
       "      <td>2588</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          token  frequency\n",
       "0        sexual      30497\n",
       "408       rough      11049\n",
       "5         story       6005\n",
       "4         crime       6004\n",
       "430       quest       5933\n",
       "2159      ether       5396\n",
       "28       friend       5367\n",
       "2090      belie       5095\n",
       "142       trans       4636\n",
       "305       plain       4300\n",
       "7         world       4166\n",
       "12        media       4058\n",
       "14       gender       4027\n",
       "6       culture       3918\n",
       "2987    politic       3867\n",
       "11       mental       3750\n",
       "1         often       3558\n",
       "2        social       3256\n",
       "8         human       3146\n",
       "3        little       2895\n",
       "1593     selves       2731\n",
       "545     persona       2719\n",
       "9         wrote       2671\n",
       "3159      versa       2637\n",
       "15    professor       2588"
      ]
     },
     "execution_count": 160,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(cluster4).sort_values(by=['frequency'], ascending=False).head(25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
