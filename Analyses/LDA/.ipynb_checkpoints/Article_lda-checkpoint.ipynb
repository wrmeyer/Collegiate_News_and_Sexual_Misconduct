{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "location = str(os.getcwd())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11768\n"
     ]
    }
   ],
   "source": [
    "f = (location[:-8] + \"Articles\\\\articles_cleaned.csv\")\n",
    "df = pd.read_csv(f)\n",
    "df = df.to_dict(\"index\")\n",
    "print(len(df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\wilmd\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import gensim\n",
    "from gensim.utils import simple_preprocess\n",
    "from gensim.parsing.preprocessing import STOPWORDS\n",
    "from nltk.stem import WordNetLemmatizer, SnowballStemmer\n",
    "from nltk.stem.porter import *\n",
    "import numpy as np\n",
    "stemmer = PorterStemmer()\n",
    "np.random.seed(2018)\n",
    "import nltk\n",
    "nltk.download('wordnet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lemmatize_stemming(text):\n",
    "    return stemmer.stem(WordNetLemmatizer().lemmatize(text, pos='v'))\n",
    "\n",
    "def preprocess(text):\n",
    "    result = []\n",
    "    for word in text:\n",
    "        word.replace(\"\\n\", \"\")\n",
    "    for token in gensim.utils.simple_preprocess(text):\n",
    "        if token not in gensim.parsing.preprocessing.STOPWORDS and len(token) > 3:\n",
    "            result.append(lemmatize_stemming(token))\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    [year, offic, women, affair, work, improv, liv...\n",
       "1    [third, time, offic, student, associ, administ...\n",
       "Name: body, dtype: object"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_clean = []\n",
    "for i in range(len(df)):\n",
    "    body = df[i][\"body\"]\n",
    "    if len(str(body)) > 100:\n",
    "        df_clean.append(df[i])\n",
    "\n",
    "df = pd.DataFrame(df_clean)\n",
    "processed_docs = df['body'].map(preprocess)\n",
    "processed_docs[:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 accomplish\n",
      "1 achiev\n",
      "2 addit\n",
      "3 address\n",
      "4 affair\n",
      "5 aim\n",
      "6 alex\n",
      "7 alyc\n",
      "8 anniversari\n",
      "9 assault\n",
      "10 assensoh\n"
     ]
    }
   ],
   "source": [
    "dictionary = gensim.corpora.Dictionary(processed_docs)\n",
    "count = 0\n",
    "for k, v in dictionary.iteritems():\n",
    "    print(k, v)\n",
    "    count += 1\n",
    "    if count > 10:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "dictionary.filter_extremes(no_below=15, no_above=0.5, keep_n=100000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(9, 1),\n",
       " (16, 4),\n",
       " (48, 1),\n",
       " (60, 1),\n",
       " (66, 5),\n",
       " (76, 1),\n",
       " (77, 3),\n",
       " (85, 2),\n",
       " (94, 1),\n",
       " (95, 1),\n",
       " (128, 1),\n",
       " (139, 1),\n",
       " (152, 1),\n",
       " (163, 1),\n",
       " (164, 1),\n",
       " (165, 1),\n",
       " (192, 9),\n",
       " (235, 2),\n",
       " (307, 1),\n",
       " (313, 3),\n",
       " (348, 8),\n",
       " (368, 1),\n",
       " (392, 1),\n",
       " (418, 1),\n",
       " (426, 1),\n",
       " (427, 1),\n",
       " (435, 2),\n",
       " (446, 5),\n",
       " (485, 1),\n",
       " (490, 1),\n",
       " (498, 1),\n",
       " (531, 1),\n",
       " (561, 1),\n",
       " (580, 1),\n",
       " (593, 1),\n",
       " (645, 1),\n",
       " (647, 5),\n",
       " (659, 1),\n",
       " (661, 1),\n",
       " (663, 1),\n",
       " (673, 2),\n",
       " (771, 1),\n",
       " (796, 2),\n",
       " (812, 3),\n",
       " (833, 3),\n",
       " (837, 1),\n",
       " (887, 2),\n",
       " (912, 1),\n",
       " (948, 1),\n",
       " (951, 1),\n",
       " (953, 1),\n",
       " (1089, 4),\n",
       " (1152, 1),\n",
       " (1189, 2),\n",
       " (1310, 8),\n",
       " (1385, 2),\n",
       " (1391, 1),\n",
       " (1420, 1),\n",
       " (1506, 1),\n",
       " (1511, 1),\n",
       " (1535, 1),\n",
       " (1546, 1),\n",
       " (1562, 1),\n",
       " (1600, 1),\n",
       " (1639, 2),\n",
       " (1687, 2),\n",
       " (1694, 2),\n",
       " (1938, 2),\n",
       " (2245, 1),\n",
       " (2419, 2),\n",
       " (2432, 2),\n",
       " (2630, 1),\n",
       " (2665, 1),\n",
       " (2668, 7),\n",
       " (2694, 1),\n",
       " (2708, 1),\n",
       " (3194, 1),\n",
       " (3210, 1),\n",
       " (3356, 1),\n",
       " (3460, 1),\n",
       " (3534, 1),\n",
       " (3622, 3),\n",
       " (3652, 2),\n",
       " (3876, 1),\n",
       " (3934, 1),\n",
       " (3972, 2),\n",
       " (4041, 1),\n",
       " (4047, 4),\n",
       " (4311, 1),\n",
       " (4731, 1),\n",
       " (5059, 3),\n",
       " (5363, 1),\n",
       " (5622, 1),\n",
       " (5637, 1),\n",
       " (6967, 1),\n",
       " (7678, 8),\n",
       " (7732, 1),\n",
       " (8605, 1),\n",
       " (9264, 1),\n",
       " (9266, 2)]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bow_corpus = [dictionary.doc2bow(doc) for doc in processed_docs]\n",
    "bow_corpus[4310]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(0, 0.06880609740257658),\n",
      " (1, 0.06509344441491738),\n",
      " (2, 0.0701658273096496),\n",
      " (3, 0.03364718834587011),\n",
      " (4, 0.050342688201998775),\n",
      " (5, 0.05711566053241263),\n",
      " (6, 0.4074097281239004),\n",
      " (7, 0.09820331436345538),\n",
      " (8, 0.014887158258429515),\n",
      " (9, 0.030700609693560147),\n",
      " (10, 0.034954516317787454),\n",
      " (11, 0.06530193759947572),\n",
      " (12, 0.0644801306157036),\n",
      " (13, 0.053337979240499725),\n",
      " (14, 0.08557610515631152),\n",
      " (15, 0.05675026683555223),\n",
      " (16, 0.03712064352024307),\n",
      " (17, 0.03748410174834358),\n",
      " (18, 0.07471874815560295),\n",
      " (19, 0.08909428632500821),\n",
      " (20, 0.05561150995460541),\n",
      " (21, 0.028382326480937855),\n",
      " (22, 0.24086436118944424),\n",
      " (23, 0.09988048060745161),\n",
      " (24, 0.04113807667021769),\n",
      " (25, 0.03235568485257175),\n",
      " (26, 0.10477550420030497),\n",
      " (27, 0.04912679132513904),\n",
      " (28, 0.10805148472697858),\n",
      " (29, 0.05122286007349925),\n",
      " (30, 0.04989599044390488),\n",
      " (31, 0.043504611697915085),\n",
      " (32, 0.03254791915657173),\n",
      " (33, 0.12409604978352705),\n",
      " (34, 0.08450133664346919),\n",
      " (35, 0.04072148934763586),\n",
      " (36, 0.025882416577499096),\n",
      " (37, 0.11138165776805362),\n",
      " (38, 0.04977579857227809),\n",
      " (39, 0.08024846188269856),\n",
      " (40, 0.03503343690889153),\n",
      " (41, 0.07413223992109928),\n",
      " (42, 0.082504265068517),\n",
      " (43, 0.08766158779984583),\n",
      " (44, 0.0973342013305354),\n",
      " (45, 0.1441382531422511),\n",
      " (46, 0.05348051987296672),\n",
      " (47, 0.07277548757598494),\n",
      " (48, 0.04133993890808692),\n",
      " (49, 0.06505199357614318),\n",
      " (50, 0.08586982620572566),\n",
      " (51, 0.0732272767643735),\n",
      " (52, 0.20360744673817932),\n",
      " (53, 0.052985813099218564),\n",
      " (54, 0.043593648909087235),\n",
      " (55, 0.03501367887615262),\n",
      " (56, 0.07110753363909118),\n",
      " (57, 0.04601889216828244),\n",
      " (58, 0.033189672523907705),\n",
      " (59, 0.07003000100881629),\n",
      " (60, 0.017252862597594256),\n",
      " (61, 0.08842482249707544),\n",
      " (62, 0.038731491443656306),\n",
      " (63, 0.045136169457852336),\n",
      " (64, 0.03662429897369987),\n",
      " (65, 0.06637670611231805),\n",
      " (66, 0.028367940354614374),\n",
      " (67, 0.04318965434143683),\n",
      " (68, 0.03107362884805653),\n",
      " (69, 0.037606669135236116),\n",
      " (70, 0.02695684897291722),\n",
      " (71, 0.04478693817086087),\n",
      " (72, 0.018865965133607387),\n",
      " (73, 0.06079462450276645),\n",
      " (74, 0.04637247326666088),\n",
      " (75, 0.061578415356554096),\n",
      " (76, 0.01868399792686627),\n",
      " (77, 0.04257770376712854),\n",
      " (78, 0.036979176299841786),\n",
      " (79, 0.07102661311461561),\n",
      " (80, 0.07852587042906242),\n",
      " (81, 0.05149746403568081),\n",
      " (82, 0.04788613851346831),\n",
      " (83, 0.07155455629291742),\n",
      " (84, 0.10318334169222751),\n",
      " (85, 0.022755784221453825),\n",
      " (86, 0.054758261973759076),\n",
      " (87, 0.08103324770473933),\n",
      " (88, 0.10218537250360414),\n",
      " (89, 0.08157284985485366),\n",
      " (90, 0.11397222130024595),\n",
      " (91, 0.1395747238139543),\n",
      " (92, 0.11232797476791828),\n",
      " (93, 0.052096955203295055),\n",
      " (94, 0.03953679690830258),\n",
      " (95, 0.061401219387120294),\n",
      " (96, 0.04588574864059693),\n",
      " (97, 0.05234386466327362),\n",
      " (98, 0.045104179539933224),\n",
      " (99, 0.02988869717842724),\n",
      " (100, 0.05641854393628809),\n",
      " (101, 0.08308365844850468),\n",
      " (102, 0.029757665790655752),\n",
      " (103, 0.03092687297225683),\n",
      " (104, 0.05816209450115757),\n",
      " (105, 0.03287525345132363),\n",
      " (106, 0.09966334506675219),\n",
      " (107, 0.09721940628183572),\n",
      " (108, 0.11164739603538666),\n",
      " (109, 0.04316676489766898),\n",
      " (110, 0.14624540883447745),\n",
      " (111, 0.04720379124143178),\n",
      " (112, 0.09559015251458265),\n",
      " (113, 0.07388178866387843),\n",
      " (114, 0.05505853983561136),\n",
      " (115, 0.06176294032855035),\n",
      " (116, 0.0413265885462673),\n",
      " (117, 0.06396273662046847),\n",
      " (118, 0.028562991440224984),\n",
      " (119, 0.040221812783566825),\n",
      " (120, 0.038861600421593916),\n",
      " (121, 0.042591875828654306),\n",
      " (122, 0.03946340491674695),\n",
      " (123, 0.041380041106293494),\n",
      " (124, 0.1465722430370544),\n",
      " (125, 0.2580658164908163),\n",
      " (126, 0.11045136888536768),\n",
      " (127, 0.07004711112732764),\n",
      " (128, 0.05816209450115757),\n",
      " (129, 0.039378104569126056),\n",
      " (130, 0.06971725800647804),\n",
      " (131, 0.03555379621660659),\n",
      " (132, 0.05350437120413297),\n",
      " (133, 0.060492648852651425),\n",
      " (134, 0.05024032653204989),\n",
      " (135, 0.03540236174271371),\n",
      " (136, 0.06650946300098098),\n",
      " (137, 0.04322513093030226),\n",
      " (138, 0.023712469357985006),\n",
      " (139, 0.01754681558560025),\n",
      " (140, 0.03170485288125114),\n",
      " (141, 0.06714036547928268),\n",
      " (142, 0.04147391246020506),\n",
      " (143, 0.11622744881626876),\n",
      " (144, 0.022805352001043094),\n",
      " (145, 0.07545403034126791),\n",
      " (146, 0.07178169555961857),\n",
      " (147, 0.05156813490425407),\n",
      " (148, 0.033472153495900034),\n",
      " (149, 0.11827484122849828),\n",
      " (150, 0.11228443428774298),\n",
      " (151, 0.07301633381580926)]\n"
     ]
    }
   ],
   "source": [
    "from gensim import corpora, models\n",
    "tfidf = models.TfidfModel(bow_corpus)\n",
    "corpus_tfidf = tfidf[bow_corpus]\n",
    "from pprint import pprint\n",
    "for doc in corpus_tfidf:\n",
    "    pprint(doc)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "lda_model = gensim.models.LdaMulticore(bow_corpus, num_topics=10, id2word=dictionary, passes=2, workers=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Topic: 0 \n",
      "Words: 0.005*\"work\" + 0.005*\"women\" + 0.005*\"think\" + 0.004*\"know\" + 0.004*\"campu\" + 0.004*\"commun\" + 0.004*\"want\" + 0.003*\"feel\" + 0.003*\"stanford\" + 0.003*\"experi\"\n",
      "Topic: 1 \n",
      "Words: 0.009*\"victim\" + 0.007*\"polic\" + 0.007*\"state\" + 0.007*\"assault\" + 0.006*\"charg\" + 0.006*\"report\" + 0.006*\"counti\" + 0.005*\"case\" + 0.005*\"court\" + 0.005*\"crime\"\n",
      "Topic: 2 \n",
      "Words: 0.021*\"assault\" + 0.018*\"report\" + 0.016*\"polic\" + 0.011*\"campu\" + 0.010*\"victim\" + 0.009*\"crime\" + 0.008*\"offic\" + 0.008*\"accord\" + 0.007*\"investig\" + 0.007*\"case\"\n",
      "Topic: 3 \n",
      "Words: 0.008*\"state\" + 0.005*\"right\" + 0.004*\"research\" + 0.004*\"women\" + 0.004*\"abort\" + 0.004*\"work\" + 0.004*\"wisconsin\" + 0.004*\"think\" + 0.003*\"school\" + 0.003*\"percent\"\n",
      "Topic: 4 \n",
      "Words: 0.008*\"polici\" + 0.005*\"campu\" + 0.005*\"state\" + 0.005*\"women\" + 0.005*\"presid\" + 0.004*\"chang\" + 0.004*\"work\" + 0.004*\"school\" + 0.004*\"think\" + 0.004*\"issu\"\n",
      "Topic: 5 \n",
      "Words: 0.004*\"stori\" + 0.004*\"world\" + 0.004*\"film\" + 0.004*\"think\" + 0.003*\"know\" + 0.003*\"thing\" + 0.003*\"live\" + 0.003*\"write\" + 0.003*\"life\" + 0.003*\"feel\"\n",
      "Topic: 6 \n",
      "Words: 0.006*\"state\" + 0.005*\"stanford\" + 0.004*\"work\" + 0.003*\"know\" + 0.003*\"assault\" + 0.003*\"go\" + 0.003*\"game\" + 0.003*\"report\" + 0.003*\"coach\" + 0.003*\"right\"\n",
      "Topic: 7 \n",
      "Words: 0.013*\"women\" + 0.005*\"know\" + 0.005*\"think\" + 0.005*\"go\" + 0.005*\"want\" + 0.005*\"event\" + 0.005*\"assault\" + 0.004*\"violenc\" + 0.004*\"campu\" + 0.004*\"drink\"\n",
      "Topic: 8 \n",
      "Words: 0.012*\"team\" + 0.007*\"assault\" + 0.006*\"game\" + 0.006*\"season\" + 0.005*\"player\" + 0.005*\"play\" + 0.005*\"stanford\" + 0.004*\"coach\" + 0.004*\"minnesota\" + 0.004*\"point\"\n",
      "Topic: 9 \n",
      "Words: 0.009*\"campu\" + 0.007*\"assault\" + 0.006*\"work\" + 0.006*\"polici\" + 0.006*\"issu\" + 0.005*\"senat\" + 0.005*\"member\" + 0.005*\"educ\" + 0.005*\"committe\" + 0.005*\"commun\"\n"
     ]
    }
   ],
   "source": [
    "for idx, topic in lda_model.print_topics(-1):\n",
    "    print('Topic: {} \\nWords: {}'.format(idx, topic))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
